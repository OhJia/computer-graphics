<html>
<head>
  <meta name="format-detection" content="telephone=no">
  <meta name="msapplication-tap-highlight" content="no">
  <meta name="viewport" content="user-scalable=no, initial-scale=1, maximum-scale=1, minimum-scale=1, width=device-width">
  <link href='https://fonts.googleapis.com/css?family=Roboto+Slab' rel='stylesheet' type='text/css'>
  <style>
    *{font-family: 'Roboto Slab', 'Georgia', serif;}
    html, body {
      margin: 0px;
      padding: 0px;
    }
    p {
      position: fixed;
      z-index: 10;
      top: 20px;
      left: 0;
      right: 0;
      text-align: center;
    }
  </style>
</head>
<body>
<script>
  /*
   * Debug parameters.
   */
  WebVRConfig = {
    /**
     * webvr-polyfill configuration
     */

    // Forces availability of VR mode.
    FORCE_ENABLE_VR: true, // Default: false.
    // Complementary filter coefficient. 0 for accelerometer, 1 for gyro.
    //K_FILTER: 0.98, // Default: 0.98.
    // How far into the future to predict during fast motion.
    //PREDICTION_TIME_S: 0.050, // Default: 0.050s.

    /**
     * webvr-boilerplate configuration
     */
    // Forces distortion in VR mode.
    //FORCE_DISTORTION: true, // Default: false.
    // Override the distortion background color.
    //DISTORTION_BGCOLOR: {x: 1, y: 0, z: 0, w: 1}, // Default: (0,0,0,1).
};
</script>

<!--
  three.js 3d library
  -->
<script src="third-party/threejs/three.js"></script>
<!--
  VRControls.js acquires positional information from connected VR devices and applies the transformations to a three.js camera object.
   -->
<script src="third-party/threejs/VRControls.js"></script>

<!--
  VREffect.js handles stereo camera setup and rendering.
  -->
<script src="third-party/threejs/VREffect.js"></script>

<!--
  A polyfill for WebVR using the Device{Motion,Orientation}Event API.
  -->
<script src="third-party/webvr-polyfill.js"></script>

<!--
  Helps enter and exit VR mode, provides best practices while in VR.
  -->
<script src="third-party/webvr-manager.js"></script>

<script src=CT_Modeler.js></script>
<script src=CT_Path.js></script>
<script src=arc-to.js></script>
<script src=drawOnMe.js></script>


<script>

var pi = Math.PI;
var isDrawing = false;
var newDrawing = false;


var vertices = arc(0, 0, 1, 0, Math.PI*1.5, false, 10);
// vertices = vertices.map()
var vert = new Float32Array(drawOnMe);
// vertices = vertices.map()
var vert2;

var renderer, canvas, scene, camera, controls, effect, manager;
var line;

function init() {
  var sin = Math.sin, cos = Math.cos, PI = Math.PI;
  canvas1.width = window.innerWidth;
  canvas1.height = window.innerHeight;
  window.scene = new CT.Scene(canvas1);
  scene.setLight(0, [1,1,1]);
  /*
    VR mode using webvr manager (polyfill), VReffect, and VRcontrol.
    still need to write VRcontrol.
  */

  //Setup three.js WebGL renderer
  // renderer = new THREE.WebGLRenderer({ antialias: true });
  // renderer.setPixelRatio(window.devicePixelRatio);
  // renderer.setSize( 512, 512 );

  // canvas = document.getElementById("canvas1");
  // canvas.width = window.innerWidth;
  // canvas.height = window.innerHeight;
  // // Append the canvas element created by the renderer to document body element.
  // canvas.appendChild(renderer.domElement);
  // // Create a three.js scene.
  // scene = new THREE.Scene();
  // // Create a three.js camera.
  // //var camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 10000);
  // camera = new THREE.PerspectiveCamera(45, 1, 1, 1000);
  // //scene.add(camera)

  // // Apply VR headset positional data to camera.
  // controls = new THREE.VRControls(camera);

  // // Apply VR stereo rendering to renderer.
  // effect = new THREE.VREffect(renderer);
  // effect.setSize(window.innerWidth, window.innerHeight);


  // // Create a VR manager helper to enter and exit VR mode.
  // manager = new WebVRManager(renderer, effect, {hideButton: false});

  // // 3d-drawing
  // camera.position.z = 4;
  // var cameraRig = new THREE.Object3D();
  // cameraRig.add(camera);
  // scene.add(cameraRig);


  /*
    End of VR and THREE.js
  */

  canvas1.addEventListener('mousedown', _onPress);
  canvas1.addEventListener('mouseup', _onRelease);
  canvas1.addEventListener('mouseout', _onRelease);
  canvas1.addEventListener('mousemove', _onMove);
  canvas1.addEventListener('touchstart', _onPress);
  canvas1.addEventListener('touchend', _onRelease);
  canvas1.addEventListener('touchcancel', _onRelease);
  canvas1.addEventListener('touchmove', _onMove);

  window.obj = new CT.Node().scale(0.8);
  scene.add(obj); // THIS


  var ctPath = new CT.Path().identity();
  ctPath.setLineWidth(0.025, 0.002);
  ctPath.setFill(false);
  ctPath.setPath(vert);
  console.log(vert);
  obj.addChild(ctPath);
  // var material = new THREE.LineBasicMaterial({
  //      color: 0x0000ff
  // });

  // var geometry = new THREE.Geometry();
  //   geometry.vertices.push(new THREE.Vector3(-10, 0, 0));
  //   geometry.vertices.push(new THREE.Vector3(0, 10, 0));
  //   geometry.vertices.push(new THREE.Vector3(10, 0, 0));

  // line = new THREE.Line(geometry, material);
  // scene.add(line);


}

function update() {
  // Update VR headset position and apply to camera.
  //controls.update();

  // Render the scene through the manager.
  //manager.render(scene, camera, time);

  //line.rotateY(time);
  // renderer.render(scene, camera);

  for (var i = 0 ; i < obj.numChildren() ; i++) {
    if(!isDrawing) {
      obj.getChild(i).identity().translate(i, 0, 0).rotateY(time).rotateX(time/2);
    } else {
      obj.getChild(i).identity().translate(i, 0, 0).rotateY(0).rotateX(0);
    }
  }
  console.log('c')
  obj.draw();
}

setTimeout(function() {
  init();
  setInterval(function() {
                 window.time = (new Date()).getTime() / 1000;
                 update();
              }, 16);
}, 100);



var drawCTPath, drawVert = [];
var count = 0;
function _onPress(evt) { 
  isDrawing = true;
  newDrawing = true;

  count = 2;
  
  console.log("DRAWING? " + isDrawing);
  //var vertices2 = arc(evt.offsetX, evt.offsetY, 1, 0, Math.PI*1.5, false, 15);
  // vertices = vertices.map()
  var x = (evt.layerX - canvas1.width/2) * 2/canvas1.width;
  var y = (evt.layerY - canvas1.height/2) * 2/canvas1.height;
  drawVert = [x, -y, x, x, -y, 0.2];
  var vert2 = new Float32Array(drawVert);
  

  // obj.getChild(0) = new CT.Path();
  //   obj.getChild(0).setLineWidth(0.01, 0.015);
  //   obj.getChild(0).setFill(false);

  obj.getChild(0).setPath(vert2);
  console.log(x,y)
  //obj.addChild(drawCTPath);
  //obj.getChild(1).identity().translate(-20, 2, 0);
  console.log('b')
  //scene.add(obj);

//console.log(obj.numChildren());

};

function _onRelease(evt) {
  if(isDrawing) {
    isDrawing = false; 
    // console.log(drawVert);
    //document.getElementById('vert').innerHTML = drawVert
    drawVert = [];
    drawCTPath = null;
    count = 0;
  }

};

function _onMove(evt) {
  if(isDrawing) {
    console.log(evt);
    newDrawing = false;
    //var vertices = arc(evt.offsetX, evt.offsetY, 1, 0, Math.PI*1.5, false, 10);
    arc(evt.layerX, evt.layerY, 5, 0, 2 * Math.PI, false);
    var x = (evt.layerX - canvas1.width/2) * 2/canvas1.width;
    var y = (evt.layerY - canvas1.height/2) * 2/canvas1.height;
    drawVert.push(x);
    drawVert.push(-y);
    drawVert.push(x);
    console.log(x, y)
    // vertices = vertices.map()
    vert2 = new Float32Array(drawVert);
    obj.getChild(0).setPath(vert2);
    count++;
  }
};

</script>
<center>
<canvas id="canvas1"></canvas>
<p>Click and drag to draw</p>
<span id="vert" />
</center>
</body>
</html>
